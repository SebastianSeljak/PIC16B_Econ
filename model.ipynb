{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "conn = sql.connect(\"states.db\")\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables_df = pd.read_sql(tables_query, conn)\n",
    "table_names = tables_df['name'].tolist()[1:]\n",
    "\n",
    "\n",
    "dataframes = {}\n",
    "for table_name in table_names:\n",
    "    dataframes[table_name] = pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_rate = dataframes['unemployment_rate']\n",
    "state_survival_rates = dataframes['survival_rates']\n",
    "industry_survival_rates = dataframes['industry_survival_rates']\n",
    "establishments = dataframes['establishments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reformatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat into 1530 samples for state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_survival_rates_filtered = state_survival_rates[state_survival_rates[\"Year Established\"] != state_survival_rates[\"Year\"]]\n",
    "state_survival_rates_filtered.loc[:, \"Year\"] = state_survival_rates_filtered[\"Year\"].astype('int')\n",
    "state_survival_rates_filtered.loc[:, \"Survival Rates of Previous Year's Survivors\"] = state_survival_rates_filtered[\"Survival Rates of Previous Year's Survivors\"].astype('float')\n",
    "state_survival_rates_filtered.loc[:, 'Surviving Establishments'] = state_survival_rates_filtered['Surviving Establishments'].str.replace(',', '').astype(int)\n",
    "state_survival_rates_grouped = state_survival_rates_filtered.groupby([\"Year\", \"State\"]).apply(lambda x: np.average(x['Survival Rates of Previous Year\\'s Survivors'], weights=x['Surviving Establishments']))\n",
    "#print(state_survival_rates_filtered.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get reformatted industry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Year Established  Year Surviving Establishments  \\\n",
      "1             1994  1995                     5537   \n",
      "2             1994  1996                     4826   \n",
      "3             1994  1997                     4406   \n",
      "4             1994  1998                     4005   \n",
      "5             1994  1999                     3729   \n",
      "\n",
      "  Total Employment of Survivors Survival Rates Since Birth  \\\n",
      "1                        51,066                       82.1   \n",
      "2                        48,263                       71.6   \n",
      "3                        47,634                       65.4   \n",
      "4                        45,444                       59.4   \n",
      "5                        39,377                       55.3   \n",
      "\n",
      "  Survival Rates of Previous Year's Survivors Average Employment of Survivors  \\\n",
      "1                                        82.1                             9.2   \n",
      "2                                        87.2                            10.0   \n",
      "3                                        91.3                            10.8   \n",
      "4                                        90.9                            11.3   \n",
      "5                                        93.1                            10.6   \n",
      "\n",
      "                                     Industry  \n",
      "1  Agriculture, Forestry, Fishing and Hunting  \n",
      "2  Agriculture, Forestry, Fishing and Hunting  \n",
      "3  Agriculture, Forestry, Fishing and Hunting  \n",
      "4  Agriculture, Forestry, Fishing and Hunting  \n",
      "5  Agriculture, Forestry, Fishing and Hunting  \n"
     ]
    }
   ],
   "source": [
    "industry_survival_rates_filtered = industry_survival_rates[industry_survival_rates[\"Year Established\"] != industry_survival_rates[\"Year\"]]\n",
    "industry_survival_rates_filtered.loc[:, \"Year\"] = industry_survival_rates_filtered[\"Year\"].astype('int')\n",
    "industry_survival_rates_filtered.loc[:, \"Survival Rates of Previous Year's Survivors\"] = industry_survival_rates_filtered[\"Survival Rates of Previous Year's Survivors\"].astype('float')\n",
    "industry_survival_rates_filtered.loc[:, 'Surviving Establishments'] = industry_survival_rates_filtered['Surviving Establishments'].str.replace(',', '').astype(int)\n",
    "industry_survival_rates_grouped = industry_survival_rates_filtered.groupby([\"Year\", \"Industry\"]).apply(lambda x: np.average(x['Survival Rates of Previous Year\\'s Survivors'], weights=x['Surviving Establishments']))\n",
    "\n",
    "print(industry_survival_rates_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_survival_rate = pd.concat([state_survival_rates_filtered, industry_survival_rates_filtered])\n",
    "total_survival_rate_grouped = total_survival_rate.groupby([\"Year\"]).apply(lambda x: np.average(x['Survival Rates of Previous Year\\'s Survivors'], weights=x['Surviving Establishments']))\n",
    "# ^ overall business survival rate by year\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year State                                       Industry  \\\n",
      "0  1995    AL     Agriculture, Forestry, Fishing and Hunting   \n",
      "1  1995    AL  Mining, Quarrying, and Oil and Gas Extraction   \n",
      "2  1995    AL                                      Utilities   \n",
      "3  1995    AL                                   Construction   \n",
      "4  1995    AL                                  Manufacturing   \n",
      "\n",
      "   P_Survival_given_State_Sector  \n",
      "0                       0.976189  \n",
      "1                       0.254581  \n",
      "2                       0.319087  \n",
      "3                     100.164821  \n",
      "4                       0.442390  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_bayesian_survival_probabilities(state_survival_rates_filtered, industry_survival_rates_filtered):\n",
    "    probabilities = []\n",
    "    years = state_survival_rates_filtered['Year'].unique() # loop through the unique years in the list\n",
    "\n",
    "    # P(Survival | State, Sector) = P(Survival) * P(State, Sector | Survival)P(State, Sector)\n",
    "    \n",
    "    for year in years:\n",
    "        df_s = state_survival_rates_filtered[state_survival_rates_filtered['Year'] == year] # data during the current iterated year\n",
    "        df_i = industry_survival_rates_filtered[industry_survival_rates_filtered['Year'] == year]\n",
    "        df_state = df_s.copy()\n",
    "        df_industry = df_i.copy()\n",
    "       \n",
    "        df_state.loc[:, 'Total Establishments'] = df_s['Surviving Establishments'].shift(1).fillna(df_s['Surviving Establishments'])\n",
    "        # total establishments is just the surviving number from the last year\n",
    "        df_industry.loc[:, 'Total Establishments'] = df_i['Surviving Establishments'].shift(1).fillna(df_i['Surviving Establishments'])\n",
    "        # making sure the first one has data to shift down also\n",
    "        \n",
    "        total_state_survivors = df_state['Surviving Establishments'].sum()\n",
    "        total_industry_survivors = df_industry['Surviving Establishments'].sum()\n",
    "        total_survivors = (total_state_survivors + total_industry_survivors) / 2  # still using weighted average for now\n",
    "        \n",
    "        total_state_establishments = df_state['Total Establishments'].sum()\n",
    "        total_industry_establishments = df_industry['Total Establishments'].sum()\n",
    "        total_establishments = (total_state_establishments + total_industry_establishments) / 2\n",
    "        \n",
    "        p_survival = total_survivors / total_establishments if total_establishments > 0 else 0  # P(Survival)\n",
    "        \n",
    "        # Compute P(State, Sector) - probability of being in a state-sector\n",
    "        df_state.loc[:, 'P_State'] = df_state['Total Establishments'] / total_state_establishments\n",
    "        df_industry.loc[:, 'P_Sector'] = df_industry['Total Establishments'] / total_industry_establishments\n",
    "        \n",
    "        # Compute P(State | Survival) and P(Sector | Survival)\n",
    "        df_state['P_State_given_Survival'] = df_state['Surviving Establishments'] / total_state_survivors\n",
    "        df_industry['P_Sector_given_Survival'] = df_industry['Surviving Establishments'] / total_industry_survivors\n",
    "        \n",
    "        # Merge datasets on state and industry\n",
    "        df_merged = pd.merge(df_state, df_industry, on='Year', suffixes=('_State', '_Sector'))\n",
    "        \n",
    "        # Compute P(Survival | State, Sector) using Bayesian formula\n",
    "        df_merged['P_Survival_given_State_Sector'] = (\n",
    "            p_survival * df_merged['P_State_given_Survival'] * df_merged['P_Sector_given_Survival'] /\n",
    "            (df_merged['P_State'] * df_merged['P_Sector'])\n",
    "        ).fillna(0)  # Handle divide-by-zero cases\n",
    "        \n",
    "        probabilities.append(df_merged[['Year', 'State', 'Industry', 'P_Survival_given_State_Sector']])\n",
    "    \n",
    "    return pd.concat(probabilities)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "bayesian_survival_probabilities = compute_bayesian_survival_probabilities(state_survival_rates_filtered, industry_survival_rates_filtered)\n",
    "print(bayesian_survival_probabilities.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Bayesian approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for (year, state), state_val in state_survival_rates_grouped.items():\n",
    "    for (ind_year, industry), ind_val in industry_survival_rates_grouped.items():\n",
    "        if year == ind_year:\n",
    "            result = (year, state, industry), (state_val * ind_val) / total_survival_rate_grouped[year]\n",
    "            results.append(result)\n",
    "\n",
    "result = pd.Series(dict(results))\n",
    "unemployment_rate[\"Year\"] = unemployment_rate[\"Year\"].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df = state_survival_rates_grouped.unstack()\n",
    "industry_df = industry_survival_rates_grouped.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_state = dict(zip(state_df.columns, range(len(state_df.columns))))\n",
    "numerical_state_rev = dict(zip(range(len(state_df.columns)), state_df.columns))\n",
    "numerical_industry = dict(zip(industry_df.columns, range(len(industry_df.columns))))\n",
    "numerical_industry_rev = dict(zip(range(len(industry_df.columns)), industry_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = []\n",
    "for year in result.index.get_level_values(0).unique():\n",
    "    for state in state_df.columns:\n",
    "        unemployment = unemployment_rate[(unemployment_rate[\"Year\"] == year) & (unemployment_rate[\"State\"] == state)][\"Unemployment Rate\"]\n",
    "        for industry in industry_df.columns:\n",
    "            response = result[year, state, industry]\n",
    "            pre_df.append((year, numerical_state[state], numerical_industry[industry], float(unemployment.iloc[0]), response))\n",
    "final_dataset = pd.DataFrame(pre_df, columns=[\"Year\", \"State\", \"Industry\", \"Unemployment Rate\", \"Response\"])\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EconDataset(Dataset):\n",
    "    def __init__(self, data, state_col, industry_col, unemployment_col, response_col):\n",
    "        self.data = data.copy()\n",
    "        self.state_col = state_col\n",
    "        self.industry_col = industry_col\n",
    "        self.unemployment_col = unemployment_col\n",
    "        self.response_col = response_col\n",
    "        self.state_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.industry_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self._preprocess_data()\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        self.encoded_states = self.state_encoder.fit_transform(self.data[[self.state_col]]) # Applying one-hot encoding to the state column\n",
    "        self.encoded_industries = self.industry_encoder.fit_transform(self.data[[self.industry_col]]) # Applying one-hot encoding to the industry\n",
    "        self.unemployment_stats = self.data[self.unemployment_col].values.reshape(-1, 1) # Turns into column vector\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        state = self.encoded_states[idx]\n",
    "        industry = self.encoded_industries[idx]\n",
    "        unemployment = self.unemployment_stats[idx]\n",
    "        predictor = np.concatenate((unemployment, state, industry), axis=0)\n",
    "        response = self.data[self.response_col].values[idx]\n",
    "        return torch.tensor(predictor, dtype=torch.float32), torch.tensor(response, dtype=torch.float32).view(1) #Response is reshaped to a column vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "SurvivalData = EconDataset(final_dataset, \"State\", \"Industry\", \"Unemployment Rate\", \"Response\")\n",
    "dataloader = DataLoader(SurvivalData, batch_size=2, shuffle=True)  # shuffle = True is important for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvivalRateModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size = 1):\n",
    "        super(SurvivalRateModel, self).__init__()\n",
    "\n",
    "        # Define layers:\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size1, hidden_size2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size2, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    \n",
    "    def train_step(self, x, y, criterion, optimizer):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = self(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def train_loop(self, dataloader, num_epochs=10, learning_rate=0.001, device = \"cpu\"):\n",
    "        self.to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        self.train() #set model to train mode.\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0\n",
    "            for x, y in dataloader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                loss = self.train_step(x, y, criterion, optimizer)\n",
    "                total_loss += loss\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = EconDataset(final_dataset, \"State\", \"Industry\", \"Unemployment Rate\", \"Response\")\n",
    "dataloader = DataLoader(data, batch_size=2, shuffle=True)\n",
    "Model = SurvivalRateModel(input_size=1 + len(data.state_encoder.categories_[0]) + len(data.industry_encoder.categories_[0]), hidden_size1=4, hidden_size2=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 393.2532\n",
      "Epoch [2/10], Loss: 13.7737\n",
      "Epoch [3/10], Loss: 13.7004\n",
      "Epoch [4/10], Loss: 13.6063\n",
      "Epoch [5/10], Loss: 13.4531\n",
      "Epoch [6/10], Loss: 13.3315\n",
      "Epoch [7/10], Loss: 13.1304\n",
      "Epoch [8/10], Loss: 13.0063\n",
      "Epoch [9/10], Loss: 12.7960\n",
      "Epoch [10/10], Loss: 12.6916\n"
     ]
    }
   ],
   "source": [
    "Model.train_loop(dataloader, num_epochs=10, learning_rate=0.001, device=\"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
